// Go ç‰ˆæœ¬çš„é«˜æ€§èƒ½ API ä»£ç†æœåŠ¡å™¨
package main

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log"
	"net"
	"net/http"
	"net/url"
	"os"
	"os/signal"
	"strings"
	"sync/atomic"
	"syscall"
	"time"

	"github.com/gin-gonic/gin"
)

// å…¨å±€å˜é‡
var (
	apiMapping = map[string]string{
		"/discord":     "https://discord.com/api",
		"/telegram":    "https://api.telegram.org",
		"/openai":      "https://api.openai.com",
		"/claude":      "https://api.anthropic.com",
		"/gemini":      "https://generativelanguage.googleapis.com",
		"/gnothink":    "https://generativelanguage.googleapis.com",
		"/meta":        "https://www.meta.ai/api",
		"/groq":        "https://api.groq.com/openai",
		"/xai":         "https://api.x.ai",
		"/cohere":      "https://api.cohere.ai",
		"/huggingface": "https://api-inference.huggingface.co",
		"/together":    "https://api.together.xyz",
		"/novita":      "https://api.novita.ai",
		"/portkey":     "https://api.portkey.ai",
		"/fireworks":   "https://api.fireworks.ai",
		"/openrouter":  "https://openrouter.ai/api",
		"/sophnet":     "https://sophnet.com/",
		"/cerebras":    "https://api.cerebras.ai",
	}
	httpClient = &http.Client{
		Timeout: 1800 * time.Second, // å¢åŠ åˆ°30åˆ†é’Ÿï¼Œé€‚åˆé•¿æ—¶é—´AIæµå¼å“åº”
		Transport: &http.Transport{
			DialContext: (&net.Dialer{
				Timeout:   15 * time.Second, // è¿æ¥è¶…æ—¶
				KeepAlive: 30 * time.Second,
			}).DialContext,
			MaxIdleConns:          256,               // å¢åŠ æœ€å¤§ç©ºé—²è¿æ¥æ•°
			MaxIdleConnsPerHost:   256,               // å¢åŠ æ¯ä¸ªä¸»æœºçš„æœ€å¤§ç©ºé—²è¿æ¥æ•°
			IdleConnTimeout:       120 * time.Second, // å¢åŠ ç©ºé—²è¿æ¥è¶…æ—¶
			ResponseHeaderTimeout: 60 * time.Second,  // å¢åŠ å“åº”å¤´è¶…æ—¶
		},
	}
)

// extractPrefixAndRest æå–å‰ç¼€å’Œå‰©ä½™è·¯å¾„
func extractPrefixAndRest(pathname string) (string, string) {
	for prefix := range apiMapping {
		if after, ok := strings.CutPrefix(pathname, prefix); ok {
			return prefix, after
		}
	}
	return "", ""
}

// AsyncProxyContext å¼‚æ­¥ä»£ç†ä¸Šä¸‹æ–‡
type AsyncProxyContext struct {
	ctx          context.Context
	cancel       context.CancelFunc
	clientWriter gin.ResponseWriter
	flusher      http.Flusher
	headersSent  atomic.Bool
	startTime    time.Time
	errorCount   *int64
	requestCount *int64
}

// NewAsyncProxyContext åˆ›å»ºå¼‚æ­¥ä»£ç†ä¸Šä¸‹æ–‡
func NewAsyncProxyContext(c *gin.Context, timeout time.Duration) *AsyncProxyContext {
	ctx, cancel := context.WithTimeout(c.Request.Context(), timeout)

	var flusher http.Flusher
	if f, ok := c.Writer.(http.Flusher); ok {
		flusher = f
	}

	return &AsyncProxyContext{
		ctx:          ctx,
		cancel:       cancel,
		clientWriter: c.Writer,
		flusher:      flusher,
		startTime:    time.Now(),
		errorCount:   &errorCount,
		requestCount: &requestCount,
	}
}

// WriteHeaders å†™å…¥å“åº”å¤´ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
func (apc *AsyncProxyContext) WriteHeaders(resp *http.Response, securityHeaders map[string]string) {
	if apc.headersSent.CompareAndSwap(false, true) {
		// è®¾ç½®å“åº”çŠ¶æ€ç 
		apc.clientWriter.WriteHeader(resp.StatusCode)

		// å¤åˆ¶å“åº”å¤´
		for name, values := range resp.Header {
			for _, value := range values {
				apc.clientWriter.Header().Add(name, value)
			}
		}

		// æ·»åŠ å®‰å…¨å¤´
		for name, value := range securityHeaders {
			apc.clientWriter.Header().Set(name, value)
		}

		// ç«‹å³åˆ·æ–°å¤´éƒ¨
		if apc.flusher != nil {
			apc.flusher.Flush()
		}
	}
}

// StreamData æµå¼ä¼ è¾“æ•°æ®
func (apc *AsyncProxyContext) StreamData(data []byte) error {
	if len(data) == 0 {
		return nil
	}

	if _, err := apc.clientWriter.Write(data); err != nil {
		return err
	}

	// ç«‹å³åˆ·æ–°åˆ°å®¢æˆ·ç«¯
	if apc.flusher != nil {
		apc.flusher.Flush()
	}

	return nil
}

// handleAPIProxy å¤„ç†APIä»£ç†è¯·æ±‚ï¼ˆå¼‚æ­¥ä¼˜åŒ–ç‰ˆï¼‰
func handleAPIProxy(c *gin.Context) {
	path := c.Request.URL.Path
	prefix, rest := extractPrefixAndRest(path)
	if prefix == "" {
		atomic.AddInt64(&errorCount, 1)
		c.JSON(404, gin.H{"error": "Not Found"})
		return
	}

	// æ ¹æ®APIç«¯ç‚¹è®¾ç½®åˆé€‚çš„è¶…æ—¶æ—¶é—´
	timeout := getTimeoutForEndpoint(prefix)
	asyncCtx := NewAsyncProxyContext(c, timeout)
	defer asyncCtx.cancel()

	atomic.AddInt64(&requestCount, 1)

	// å¼‚æ­¥è®°å½•è¯·æ±‚ï¼Œé¿å…é˜»å¡ä¸»æµç¨‹
	go stats.recordRequest(prefix)

	// å‡†å¤‡å®‰å…¨å¤´
	securityHeaders := map[string]string{
		"X-Content-Type-Options": "nosniff",
		"X-Frame-Options":        "DENY",
		"Referrer-Policy":        "no-referrer",
		"X-Accel-Buffering":      "no", // ç¦ç”¨ä»£ç†ç¼“å­˜
	}

	// å¤„ç† OPTIONS è¯·æ±‚
	if c.Request.Method == "OPTIONS" {
		// å¯¹äºéæµè§ˆå™¨è¯·æ±‚ï¼Œå¯ä»¥ç›´æ¥è¿”å›æˆåŠŸ
		c.Status(http.StatusNoContent)
		return
	}

	// å¼‚æ­¥å‘é€è¯·æ±‚å¹¶æµå¼è½¬å‘å“åº”
	go func() {
		defer asyncCtx.cancel()

		if err := apc_handleAsyncAPIRequest(asyncCtx, c, prefix, rest, securityHeaders); err != nil {
			log.Printf("Async API request error: %v", err)
			atomic.AddInt64(&errorCount, 1)
		}
	}()

	// ç­‰å¾…å¼‚æ­¥å¤„ç†å®Œæˆæˆ–è¶…æ—¶
	<-asyncCtx.ctx.Done()

	// æ›´æ–°æ€§èƒ½æŒ‡æ ‡
	apc_updateResponseMetrics(asyncCtx.startTime)
}

// apc_handleAsyncAPIRequest å¼‚æ­¥å¤„ç†APIè¯·æ±‚
func apc_handleAsyncAPIRequest(asyncCtx *AsyncProxyContext, c *gin.Context, prefix, rest string, securityHeaders map[string]string) error {
	// æ„å»ºç›®æ ‡URL
	targetURL := apiMapping[prefix] + rest
	if c.Request.URL.RawQuery != "" {
		targetURL += "?" + c.Request.URL.RawQuery
	}

	// å‡†å¤‡è¯·æ±‚ä½“
	var body io.Reader
	if c.Request.Method != "GET" && c.Request.Method != "HEAD" {
		bodyBytes, err := io.ReadAll(c.Request.Body)
		if err != nil {
			return err
		}

		// ç‰¹æ®Šå¤„ç† gnothink ç«¯ç‚¹
		if prefix == "/gnothink" && c.Request.Method == "POST" &&
			strings.Contains(c.GetHeader("Content-Type"), "application/json") {
			if bodyJSON, err := fastJSONPatch(bodyBytes); err == nil {
				bodyBytes = bodyJSON
			}
		}

		body = bytes.NewReader(bodyBytes)
	}

	// åˆ›å»ºè¯·æ±‚
	req, err := http.NewRequestWithContext(asyncCtx.ctx, c.Request.Method, targetURL, body)
	if err != nil {
		return err
	}

	// å¤åˆ¶è¯·æ±‚å¤´
	commonHeaders := []string{"content-type", "authorization", "accept", "anthropic-version"}
	for _, header := range commonHeaders {
		if value := c.GetHeader(header); value != "" {
			req.Header.Set(header, value)
		}
	}

	// å¤åˆ¶ä»¥ x- å¼€å¤´çš„è‡ªå®šä¹‰å¤´
	for name, values := range c.Request.Header {
		if strings.HasPrefix(strings.ToLower(name), "x-") {
			for _, value := range values {
				req.Header.Add(name, value)
			}
		}
	}

	// APIç‰¹æ®Šå¤„ç†
	if prefix == "/claude" && req.Header.Get("anthropic-version") == "" {
		req.Header.Set("anthropic-version", "2023-06-01")
	}
	if req.Header.Get("User-Agent") == "" {
		req.Header.Set("User-Agent", "Go-API-Proxy/1.0")
	}

	// å‘é€è¯·æ±‚ï¼ˆä½¿ç”¨æ”¯æŒå–æ¶ˆçš„å®¢æˆ·ç«¯ï¼‰
	resp, err := httpClient.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	// ç«‹å³å†™å…¥å“åº”å¤´
	asyncCtx.WriteHeaders(resp, securityHeaders)

	// æ£€æŸ¥å“åº”çŠ¶æ€ç 
	if resp.StatusCode >= 400 {
		atomic.AddInt64(&errorCount, 1)
	}

	// æµå¼è½¬å‘å“åº”ä½“
	return apc_streamResponseBody(asyncCtx, resp)
}

// apc_streamResponseBody æµå¼è½¬å‘å“åº”ä½“
func apc_streamResponseBody(asyncCtx *AsyncProxyContext, resp *http.Response) error {
	// æ£€æµ‹æ˜¯å¦ä¸ºæµå¼å“åº”
	contentType := resp.Header.Get("Content-Type")
	isStreaming := strings.Contains(contentType, "text/event-stream") ||
		strings.Contains(contentType, "application/stream+json") ||
		strings.Contains(contentType, "text/plain") // OpenAIçš„æµå¼å“åº”é€šå¸¸æ˜¯text/plain

	var bufferSize int
	if isStreaming {
		bufferSize = 2 * 1024 // 2KB for streaming APIs (OpenAI, Claudeç­‰)
	} else if strings.Contains(contentType, "text/html") {
		bufferSize = 8 * 1024 // 8KB for HTML pages
	} else if strings.Contains(contentType, "application/json") {
		bufferSize = 16 * 1024 // 16KB for JSON APIs
	} else if strings.Contains(contentType, "image/") || strings.Contains(contentType, "video/") {
		bufferSize = 64 * 1024 // 64KB for media files
	} else {
		bufferSize = 32 * 1024 // 32KB for other content
	}

	buffer := make([]byte, bufferSize)

	for {
		select {
		case <-asyncCtx.ctx.Done():
			return asyncCtx.ctx.Err()
		default:
			// å¯¹äºæµå¼å“åº”ï¼Œä¸è®¾ç½®ä¸¥æ ¼çš„è¯»å–è¶…æ—¶ï¼Œè®©contextæ§åˆ¶æ•´ä½“è¶…æ—¶
			n, err := resp.Body.Read(buffer)
			if n > 0 {
				if streamErr := asyncCtx.StreamData(buffer[:n]); streamErr != nil {
					return streamErr
				}
			}

			if err != nil {
				if err == io.EOF {
					return nil // æ­£å¸¸ç»“æŸ
				}
				return err
			}
		}
	}
}

// handleProxy å¤„ç†ç½‘é¡µä»£ç†è¯·æ±‚ï¼ˆå¼‚æ­¥ä¼˜åŒ–ç‰ˆï¼‰
func handleProxy(c *gin.Context) {
	targetURLString := strings.TrimPrefix(c.Request.URL.Path, "/proxy/")
	if !strings.HasPrefix(targetURLString, "http") {
		c.String(400, "Invalid proxy URL. Must start with http:// or https:// after /proxy/")
		return
	}

	targetURL, err := url.Parse(targetURLString)
	if err != nil {
		c.String(400, "Invalid URL format")
		return
	}

	// åˆ›å»ºå¼‚æ­¥ä»£ç†ä¸Šä¸‹æ–‡
	asyncCtx := NewAsyncProxyContext(c, 120*time.Second) // 2åˆ†é’Ÿè¶…æ—¶ï¼Œé€‚åˆç½‘é¡µåŠ è½½
	defer asyncCtx.cancel()

	// å‡†å¤‡å®‰å…¨å¤´
	securityHeaders := map[string]string{
		"X-Content-Type-Options": "nosniff",
		"Referrer-Policy":        "no-referrer-when-downgrade",
		"X-Frame-Options":        "", // å…è®¸åœ¨iframeä¸­åµŒå…¥
		"X-Accel-Buffering":      "no",
	}

	// å¤„ç† OPTIONS è¯·æ±‚
	if c.Request.Method == "OPTIONS" {
		c.Status(http.StatusNoContent)
		return
	}

	// å¼‚æ­¥å‘é€è¯·æ±‚å¹¶æµå¼è½¬å‘å“åº”
	go func() {
		defer asyncCtx.cancel()

		if err := apc_handleAsyncProxyRequest(asyncCtx, c, targetURL, securityHeaders); err != nil {
			log.Printf("Async proxy request error: %v", err)
		}
	}()

	// ç­‰å¾…å¼‚æ­¥å¤„ç†å®Œæˆæˆ–è¶…æ—¶
	<-asyncCtx.ctx.Done()
}

// apc_handleAsyncProxyRequest å¼‚æ­¥å¤„ç†ä»£ç†è¯·æ±‚
func apc_handleAsyncProxyRequest(asyncCtx *AsyncProxyContext, c *gin.Context, targetURL *url.URL, securityHeaders map[string]string) error {
	// å‡†å¤‡è¯·æ±‚ä½“
	var body io.Reader
	if c.Request.Method != "GET" && c.Request.Method != "HEAD" {
		bodyBytes, err := io.ReadAll(c.Request.Body)
		if err != nil {
			return err
		}
		body = bytes.NewReader(bodyBytes)
	}

	// åˆ›å»ºè¯·æ±‚
	req, err := http.NewRequestWithContext(asyncCtx.ctx, c.Request.Method, targetURL.String(), body)
	if err != nil {
		return err
	}

	// å¤åˆ¶è¯·æ±‚å¤´
	allowedHeaders := []string{"accept", "content-type", "authorization", "user-agent",
		"accept-encoding", "accept-language", "cache-control", "pragma", "x-requested-with",
		"range", "if-range", "if-modified-since", "if-none-match"}

	for _, header := range allowedHeaders {
		if value := c.GetHeader(header); value != "" {
			req.Header.Set(header, value)
		}
	}

	// å¤„ç† referer å¤´
	if referer := c.GetHeader("referer"); referer != "" {
		req.Header.Set("referer", strings.Replace(referer,
			c.Request.URL.Scheme+"://"+c.Request.Host, targetURL.Scheme+"://"+targetURL.Host, 1))
	}

	// å‘é€è¯·æ±‚
	resp, err := httpClient.Do(req)
	if err != nil {
		return err
	}
	defer resp.Body.Close()

	// ç«‹å³å†™å…¥å“åº”å¤´
	asyncCtx.WriteHeaders(resp, securityHeaders)

	// æ ¹æ®å†…å®¹ç±»å‹é€‰æ‹©å¤„ç†æ–¹å¼
	contentType := resp.Header.Get("Content-Type")
	if strings.Contains(contentType, "text/html") {
		return apc_handleHTMLStreamRewrite(asyncCtx, resp, targetURL)
	} else {
		return apc_streamResponseBody(asyncCtx, resp)
	}
}

// apc_handleHTMLStreamRewrite å¼‚æ­¥HTMLæµå¼é‡å†™
func apc_handleHTMLStreamRewrite(asyncCtx *AsyncProxyContext, resp *http.Response, targetURL *url.URL) error {
	// åˆ›å»ºHTMLé‡å†™å™¨
	scheme := "http"
	if asyncCtx.clientWriter.Header().Get("X-Forwarded-Proto") == "https" {
		scheme = "https"
	}
	proxyBase := scheme + "://" + asyncCtx.clientWriter.Header().Get("Host") + "/proxy/"

	rewriter := &AsyncHTMLRewriter{
		asyncCtx:  asyncCtx,
		targetURL: targetURL,
		proxyBase: proxyBase,
		buffer:    make([]byte, 0, 4096), // åˆå§‹4KBï¼ŒåŠ¨æ€å¢é•¿
	}

	// æ ¹æ®Content-LengthåŠ¨æ€è°ƒæ•´ç¼“å†²åŒºå¤§å°
	contentLength := resp.ContentLength
	var bufferSize int
	if contentLength > 0 {
		if contentLength < 1024*1024 { // å°äº1MB
			bufferSize = 4 * 1024 // 4KB
		} else if contentLength < 10*1024*1024 { // å°äº10MB
			bufferSize = 16 * 1024 // 16KB
		} else {
			bufferSize = 64 * 1024 // 64KB for large pages
		}
	} else {
		bufferSize = 8 * 1024 // é»˜è®¤8KB
	}

	// æµå¼å¤„ç†HTMLå†…å®¹
	buffer := make([]byte, bufferSize)

	for {
		select {
		case <-asyncCtx.ctx.Done():
			rewriter.Flush()
			return asyncCtx.ctx.Err()
		default:
			n, err := resp.Body.Read(buffer)
			if n > 0 {
				if writeErr := rewriter.Write(buffer[:n]); writeErr != nil {
					return writeErr
				}
			}

			if err != nil {
				if err == io.EOF {
					rewriter.Flush()
					return nil
				}
				return err
			}
		}
	}
}

// AsyncHTMLRewriter å¼‚æ­¥HTMLé‡å†™å™¨
type AsyncHTMLRewriter struct {
	asyncCtx  *AsyncProxyContext
	targetURL *url.URL
	proxyBase string
	buffer    []byte
}

// Write å®ç°å¼‚æ­¥HTMLé‡å†™
func (h *AsyncHTMLRewriter) Write(data []byte) error {
	h.buffer = append(h.buffer, data...)

	processed := h.processBuffer()
	if len(processed) > 0 {
		return h.asyncCtx.StreamData(processed)
	}

	return nil
}

// processBuffer å¤„ç†HTMLç¼“å†²åŒº
func (h *AsyncHTMLRewriter) processBuffer() []byte {
	if len(h.buffer) == 0 {
		return nil
	}

	baseURL := h.targetURL.Scheme + "://" + h.targetURL.Host
	content := string(h.buffer)

	// ä¼˜åŒ–çš„URLé‡å†™æ¨¡å¼ - ä½¿ç”¨æ›´é«˜æ•ˆçš„å­—ç¬¦ä¸²æ›¿æ¢
	patterns := []struct{ old, new string }{
		{`href="` + baseURL, `href="` + h.proxyBase + baseURL},
		{`src="` + baseURL, `src="` + h.proxyBase + baseURL},
		{`action="` + baseURL, `action="` + h.proxyBase + baseURL},
		{`href='` + baseURL, `href='` + h.proxyBase + baseURL},
		{`src='` + baseURL, `src='` + h.proxyBase + baseURL},
		{`action='` + baseURL, `action='` + h.proxyBase + baseURL},
		// æ·»åŠ æ›´å¤šå¸¸è§çš„URLæ¨¡å¼
		{`url("` + baseURL, `url("` + h.proxyBase + baseURL},
		{`url('` + baseURL, `url('` + h.proxyBase + baseURL},
	}

	// æ‰¹é‡æ›¿æ¢ï¼Œå‡å°‘å­—ç¬¦ä¸²æ“ä½œæ¬¡æ•°
	for _, pattern := range patterns {
		content = strings.ReplaceAll(content, pattern.old, pattern.new)
	}

	// åŠ¨æ€è°ƒæ•´ä¿ç•™å¤§å°ï¼Œæ ¹æ®ç¼“å†²åŒºå¤§å°ä¼˜åŒ–
	keepSize := 1024             // é»˜è®¤ä¿ç•™1KB
	if len(h.buffer) > 32*1024 { // å¦‚æœç¼“å†²åŒºå¤§äº32KB
		keepSize = 2048 // ä¿ç•™2KBï¼Œå‡å°‘å¤„ç†é¢‘ç‡
	} else if len(h.buffer) < 4*1024 { // å¦‚æœç¼“å†²åŒºå°äº4KB
		keepSize = 512 // åªä¿ç•™512Bï¼Œæ›´å¿«å¤„ç†
	}

	if len(h.buffer) > keepSize {
		processed := []byte(content[:len(content)-keepSize])
		h.buffer = []byte(content[len(content)-keepSize:])
		return processed
	}

	return nil
}

// Flush åˆ·æ–°å‰©ä½™å†…å®¹
func (h *AsyncHTMLRewriter) Flush() {
	if len(h.buffer) > 0 {
		baseURL := h.targetURL.Scheme + "://" + h.targetURL.Host
		content := string(h.buffer)

		patterns := []struct{ old, new string }{
			{`href="` + baseURL, `href="` + h.proxyBase + baseURL},
			{`src="` + baseURL, `src="` + h.proxyBase + baseURL},
			{`action="` + baseURL, `action="` + h.proxyBase + baseURL},
			{`href='` + baseURL, `href='` + h.proxyBase + baseURL},
			{`src='` + baseURL, `src='` + h.proxyBase + baseURL},
			{`action='` + baseURL, `action='` + h.proxyBase + baseURL},
		}

		for _, pattern := range patterns {
			content = strings.ReplaceAll(content, pattern.old, pattern.new)
		}

		h.asyncCtx.StreamData([]byte(content))
		h.buffer = nil
	}
}

// apc_updateResponseMetrics æ›´æ–°å“åº”æŒ‡æ ‡
func apc_updateResponseMetrics(startTime time.Time) {
	responseTime := time.Since(startTime).Milliseconds()

	// ä½¿ç”¨åŸå­æ“ä½œç´¯è®¡å“åº”æ—¶é—´å’Œè®¡æ•°
	atomic.AddInt64(&responseTimeSum, responseTime)
	atomic.AddInt64(&responseTimeCount, 1)
}

// fastJSONPatch å¿«é€ŸJSONè¡¥ä¸å¤„ç†
func fastJSONPatch(bodyBytes []byte) ([]byte, error) {
	var bodyJSON map[string]interface{}
	if err := json.Unmarshal(bodyBytes, &bodyJSON); err != nil {
		return bodyBytes, err
	}

	// æ·»åŠ  thinkingConfig
	if generationConfig, ok := bodyJSON["generationConfig"].(map[string]interface{}); ok {
		generationConfig["thinkingConfig"] = map[string]interface{}{
			"thinkingBudget": 0,
		}
	} else {
		bodyJSON["generationConfig"] = map[string]interface{}{
			"thinkingConfig": map[string]interface{}{
				"thinkingBudget": 0,
			},
		}
	}
	return json.Marshal(bodyJSON)
}

// getTimeoutForEndpoint æ ¹æ®APIç«¯ç‚¹è¿”å›åˆé€‚çš„è¶…æ—¶æ—¶é—´
func getTimeoutForEndpoint(prefix string) time.Duration {
	// AIæµå¼APIéœ€è¦æ›´é•¿çš„è¶…æ—¶æ—¶é—´ - 30åˆ†é’Ÿ
	aiEndpoints := map[string]time.Duration{
		"/openai":     1800 * time.Second, // 30åˆ†é’Ÿ
		"/claude":     1800 * time.Second, // 30åˆ†é’Ÿ
		"/gemini":     1800 * time.Second, // 30åˆ†é’Ÿ
		"/gnothink":   1800 * time.Second, // 30åˆ†é’Ÿ
		"/groq":       1800 * time.Second, // 30åˆ†é’Ÿ
		"/xai":        1800 * time.Second, // 30åˆ†é’Ÿ
		"/cohere":     1800 * time.Second, // 30åˆ†é’Ÿ
		"/together":   1800 * time.Second, // 30åˆ†é’Ÿ
		"/fireworks":  1800 * time.Second, // 30åˆ†é’Ÿ
		"/openrouter": 1800 * time.Second, // 30åˆ†é’Ÿ
		"/cerebras":   1800 * time.Second, // 30åˆ†é’Ÿ
	}

	if timeout, exists := aiEndpoints[prefix]; exists {
		return timeout
	}

	// å…¶ä»–APIä½¿ç”¨è¾ƒçŸ­çš„è¶…æ—¶æ—¶é—´
	return 60 * time.Second
}

// main ä¸»å‡½æ•°
func main() {
	// è®¾ç½®ç”Ÿäº§æ¨¡å¼
	gin.SetMode(gin.ReleaseMode)

	// åˆå§‹åŒ–ç»Ÿè®¡ç³»ç»Ÿ
	initStats()

	// åˆ›å»ºè·¯ç”±
	r := gin.New()

	// æ·»åŠ æ—¥å¿—ä¸­é—´ä»¶
	r.Use(gin.LoggerWithFormatter(func(param gin.LogFormatterParams) string {
		return fmt.Sprintf("[%s] %s - \"%s %s %s\" %d %s %d %s \"%s\"\n",
			param.TimeStamp.Format("2006/01/02 - 15:04:05"), // æ—¶é—´æˆ³
			param.ClientIP,            // å®¢æˆ·ç«¯ IP
			param.Method,              // HTTP æ–¹æ³•
			param.Path,                // è¯·æ±‚è·¯å¾„
			param.Request.Proto,       // HTTP åè®® (e.g., HTTP/1.1)
			param.StatusCode,          // çŠ¶æ€ç 
			param.Latency,             // å¤„ç†å»¶è¿Ÿ
			param.BodySize,            // å“åº”ä½“å¤§å°
			param.ErrorMessage,        // é”™è¯¯ä¿¡æ¯
			param.Request.UserAgent(), // User-Agent
		)
	}))

	// æ·»åŠ æ¢å¤ä¸­é—´ä»¶
	r.Use(gin.Recovery())

	// è®¾ç½®è·¯ç”±
	r.GET("/", handleIndex)
	r.GET("/index.html", handleIndex)
	r.GET("/robots.txt", handleRobotsTxt)
	r.GET("/stats", handleStats)

	// é™æ€æ–‡ä»¶æœåŠ¡
	r.Static("/static", "./static")

	// APIä»£ç†è·¯ç”±
	for prefix := range apiMapping {
		r.Any(prefix+"/*path", handleAPIProxy)
	}

	// ç½‘é¡µä»£ç†è·¯ç”±
	r.Any("/proxy/*path", handleProxy)

	// å¯åŠ¨æœåŠ¡å™¨
	port := os.Getenv("PORT")
	if port == "" {
		port = "8000"
	}

	log.Printf("ğŸš€ APIä»£ç†æœåŠ¡å™¨å·²å¯åŠ¨ (Goä¼˜åŒ–ç‰ˆ) ç«¯å£:%s", port)
	log.Printf("ğŸ•’ ç»Ÿè®¡æ•°æ®æ¯åˆ†é’Ÿè‡ªåŠ¨åˆ·æ–°é¡µé¢")
	log.Printf("âš¡ æ€§èƒ½ä¼˜åŒ–ï¼šå¼‚æ­¥ç»Ÿè®¡ã€å†…å­˜ä¼˜åŒ–ã€é”ç«äº‰å‡å°‘")
	log.Printf("â±ï¸  è¶…æ—¶é…ç½®ï¼šAI API 30åˆ†é’Ÿï¼Œå…¶ä»–API 1åˆ†é’Ÿï¼ŒHTTPå®¢æˆ·ç«¯ 30åˆ†é’Ÿ")
	log.Printf("ğŸ“Š è®¿é—® http://localhost:%s æŸ¥çœ‹ç»Ÿè®¡ä¿¡æ¯", port)

	// ä½¿ç”¨è‡ªå®šä¹‰HTTPæœåŠ¡å™¨ä»¥æ›´å¥½åœ°æ§åˆ¶
	srv := &http.Server{
		Addr:    ":" + port,
		Handler: r,
	}

	// å¯åŠ¨æœåŠ¡å™¨
	go func() {
		if err := srv.ListenAndServe(); err != nil && err != http.ErrServerClosed {
			log.Fatalf("æœåŠ¡å™¨å¯åŠ¨å¤±è´¥: %v", err)
		}
	}()

	// ç­‰å¾…ä¸­æ–­ä¿¡å·
	quit := make(chan os.Signal, 1)
	signal.Notify(quit, os.Interrupt, syscall.SIGTERM)
	<-quit

	log.Println("æ­£åœ¨å…³é—­æœåŠ¡å™¨...")

	// ä¼˜é›…å…³é—­
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	if err := srv.Shutdown(ctx); err != nil {
		log.Fatal("æœåŠ¡å™¨å¼ºåˆ¶å…³é—­:", err)
	}

	log.Println("æœåŠ¡å™¨å·²å…³é—­")
}

// handleIndex å¤„ç†é¦–é¡µ
func handleIndex(c *gin.Context) {
	c.File("index.html")
}

// handleRobotsTxt å¤„ç†robots.txt
func handleRobotsTxt(c *gin.Context) {
	c.Header("Content-Type", "text/plain")
	c.String(200, "User-agent: *\nDisallow: /\n")
}
