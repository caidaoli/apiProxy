package stats

import (
	"context"
	"encoding/json"
	"log"
	"runtime"
	"sync"
	"sync/atomic"
	"time"

	"github.com/redis/go-redis/v9"
)

// Collector ç®€åŒ–çš„ç»Ÿè®¡æ”¶é›†å™¨
// KISSåŸåˆ™ï¼šä½¿ç”¨atomic+RWMutexï¼Œå»é™¤è¿‡åº¦ä¼˜åŒ–çš„channelå’Œæ‰¹å¤„ç†
type Collector struct {
	// åŸå­è®¡æ•°å™¨(å…¨å±€ç»Ÿè®¡)
	requestCount int64
	errorCount   int64

	// å“åº”æ—¶é—´ç»Ÿè®¡(åŸå­æ“ä½œ)
	responseTimeSum   int64 // çº³ç§’
	responseTimeCount int64

	// ç«¯ç‚¹ç»Ÿè®¡æ•°æ®(è¯»å†™é”ä¿æŠ¤)
	mu        sync.RWMutex
	endpoints map[string]*EndpointStats

	// æ—¶é—´åºåˆ—æ•°æ®(ç¯å½¢ç¼“å†²åŒº,æœ€å¤šä¿ç•™10000æ¡è®°å½•)
	requestsMu       sync.RWMutex
	requests         []RequestRecord // è¯·æ±‚æ—¶é—´æˆ³è®°å½•
	maxRequestsCache int             // æœ€å¤§ç¼“å­˜æ•°é‡

	// æ€§èƒ½æŒ‡æ ‡ç¼“å­˜
	lastMetricsUpdate time.Time
	cachedMetrics     *PerformanceMetrics

	// Rediså®¢æˆ·ç«¯(å¯é€‰æŒä¹…åŒ–)
	redisClient *redis.Client
}

// RequestRecord è¯·æ±‚è®°å½•(ç”¨äºæ—¶é—´åºåˆ—å›¾è¡¨)
type RequestRecord struct {
	Timestamp int64  `json:"timestamp"` // Unixæ—¶é—´æˆ³(ç§’)
	Endpoint  string `json:"endpoint"`  // ç«¯ç‚¹è·¯å¾„
}

// PerformanceMetrics æ€§èƒ½æŒ‡æ ‡
type PerformanceMetrics struct {
	RequestsPerSec    float64 `json:"requests_per_sec"`     // æ¯ç§’è¯·æ±‚æ•°
	AvgResponseTimeMs int64   `json:"avg_response_time_ms"` // å¹³å‡å“åº”æ—¶é—´(æ¯«ç§’)
	ErrorRate         float64 `json:"error_rate"`           // é”™è¯¯ç‡(%)
	MemoryUsageMB     float64 `json:"memory_usage_mb"`      // å†…å­˜ä½¿ç”¨(MB)
	GoroutineCount    int     `json:"goroutine_count"`      // åç¨‹æ•°é‡
}

// EndpointStats ç«¯ç‚¹ç»Ÿè®¡æ•°æ®
type EndpointStats struct {
	Count       int64 `json:"count"`
	ErrorCount  int64 `json:"error_count"`
	LastRequest int64 `json:"last_request"`
}

// NewCollector åˆ›å»ºç»Ÿè®¡æ”¶é›†å™¨
func NewCollector(redisClient *redis.Client) *Collector {
	return &Collector{
		endpoints:        make(map[string]*EndpointStats),
		requests:         make([]RequestRecord, 0, 10000),
		maxRequestsCache: 10000, // æœ€å¤šç¼“å­˜10000æ¡è®°å½•(çº¦å ç”¨200KBå†…å­˜)
		redisClient:      redisClient,
	}
}

// RecordRequest è®°å½•è¯·æ±‚
// ç®€åŒ–ç‰ˆæœ¬ï¼šç›´æ¥ä½¿ç”¨é”ï¼Œæ€§èƒ½è¶³å¤Ÿå¥½
func (c *Collector) RecordRequest(endpoint string) {
	atomic.AddInt64(&c.requestCount, 1)

	now := time.Now()
	timestamp := now.Unix()

	c.mu.Lock()
	stats := c.endpoints[endpoint]
	if stats == nil {
		stats = &EndpointStats{}
		c.endpoints[endpoint] = stats
	}
	stats.Count++
	stats.LastRequest = timestamp
	c.mu.Unlock()

	// è®°å½•æ—¶é—´åºåˆ—æ•°æ®(ç¯å½¢ç¼“å†²åŒº)
	c.requestsMu.Lock()
	if len(c.requests) >= c.maxRequestsCache {
		// åˆ é™¤æœ€æ—§çš„20%æ•°æ®,é¿å…é¢‘ç¹æ‰©å®¹
		c.requests = c.requests[c.maxRequestsCache/5:]
	}
	c.requests = append(c.requests, RequestRecord{
		Timestamp: timestamp,
		Endpoint:  endpoint,
	})
	c.requestsMu.Unlock()
}

// RecordError è®°å½•é”™è¯¯
func (c *Collector) RecordError(endpoint string) {
	atomic.AddInt64(&c.errorCount, 1)

	c.mu.Lock()
	stats := c.endpoints[endpoint]
	if stats == nil {
		stats = &EndpointStats{}
		c.endpoints[endpoint] = stats
	}
	stats.ErrorCount++
	c.mu.Unlock()
}

// UpdateResponseMetrics æ›´æ–°å“åº”æ—¶é—´ç»Ÿè®¡
func (c *Collector) UpdateResponseMetrics(duration time.Duration) {
	atomic.AddInt64(&c.responseTimeSum, int64(duration))
	atomic.AddInt64(&c.responseTimeCount, 1)
}

// GetStats è·å–ç»Ÿè®¡å¿«ç…§ï¼ˆè¯»é”ï¼Œå¿«é€Ÿï¼‰
func (c *Collector) GetStats() map[string]*EndpointStats {
	c.mu.RLock()
	defer c.mu.RUnlock()

	// æ·±æ‹·è´ï¼Œé¿å…å¤–éƒ¨ä¿®æ”¹
	result := make(map[string]*EndpointStats, len(c.endpoints))
	for k, v := range c.endpoints {
		result[k] = &EndpointStats{
			Count:       v.Count,
			ErrorCount:  v.ErrorCount,
			LastRequest: v.LastRequest,
		}
	}

	return result
}

// GetRequests è·å–è¯·æ±‚æ—¶é—´åºåˆ—æ•°æ®(ç”¨äºå›¾è¡¨)
func (c *Collector) GetRequests() []RequestRecord {
	c.requestsMu.RLock()
	defer c.requestsMu.RUnlock()

	// æ·±æ‹·è´,é¿å…å¤–éƒ¨ä¿®æ”¹
	result := make([]RequestRecord, len(c.requests))
	copy(result, c.requests)
	return result
}

// GetPerformanceMetrics è·å–æ€§èƒ½æŒ‡æ ‡(ç¼“å­˜5ç§’)
func (c *Collector) GetPerformanceMetrics() *PerformanceMetrics {
	now := time.Now()

	// å¦‚æœç¼“å­˜æœªè¿‡æœŸ,ç›´æ¥è¿”å›
	if c.cachedMetrics != nil && now.Sub(c.lastMetricsUpdate) < 5*time.Second {
		return c.cachedMetrics
	}

	// è®¡ç®—æ€§èƒ½æŒ‡æ ‡
	totalRequests := atomic.LoadInt64(&c.requestCount)
	totalErrors := atomic.LoadInt64(&c.errorCount)
	responseTimeSum := atomic.LoadInt64(&c.responseTimeSum)
	responseTimeCount := atomic.LoadInt64(&c.responseTimeCount)

	// è®¡ç®—QPS(åŸºäºæœ€è¿‘60ç§’çš„è¯·æ±‚)
	var qps float64
	c.requestsMu.RLock()
	sixtySecondsAgo := now.Unix() - 60
	recentCount := 0
	for i := len(c.requests) - 1; i >= 0; i-- {
		if c.requests[i].Timestamp >= sixtySecondsAgo {
			recentCount++
		} else {
			break
		}
	}
	c.requestsMu.RUnlock()
	qps = float64(recentCount) / 60.0

	// è®¡ç®—å¹³å‡å“åº”æ—¶é—´(æ¯«ç§’)
	var avgResponseMs int64
	if responseTimeCount > 0 {
		avgResponseMs = (responseTimeSum / responseTimeCount) / 1_000_000 // çº³ç§’è½¬æ¯«ç§’
	}

	// è®¡ç®—é”™è¯¯ç‡(%)
	var errorRate float64
	if totalRequests > 0 {
		errorRate = (float64(totalErrors) / float64(totalRequests)) * 100
	}

	// è·å–å†…å­˜å’Œåç¨‹ä¿¡æ¯
	var memStats runtime.MemStats
	runtime.ReadMemStats(&memStats)
	memoryMB := float64(memStats.Alloc) / 1024 / 1024
	goroutines := runtime.NumGoroutine()

	metrics := &PerformanceMetrics{
		RequestsPerSec:    qps,
		AvgResponseTimeMs: avgResponseMs,
		ErrorRate:         errorRate,
		MemoryUsageMB:     memoryMB,
		GoroutineCount:    goroutines,
	}

	// æ›´æ–°ç¼“å­˜
	c.cachedMetrics = metrics
	c.lastMetricsUpdate = now

	return metrics
}

// GetRequestCount è·å–æ€»è¯·æ±‚æ•°
func (c *Collector) GetRequestCount() int64 {
	return atomic.LoadInt64(&c.requestCount)
}

// GetErrorCount è·å–æ€»é”™è¯¯æ•°
func (c *Collector) GetErrorCount() int64 {
	return atomic.LoadInt64(&c.errorCount)
}

// GetAverageResponseTime è·å–å¹³å‡å“åº”æ—¶é—´
func (c *Collector) GetAverageResponseTime() time.Duration {
	sum := atomic.LoadInt64(&c.responseTimeSum)
	count := atomic.LoadInt64(&c.responseTimeCount)

	if count == 0 {
		return 0
	}

	return time.Duration(sum / count)
}

// SaveToRedis ä¿å­˜ç»Ÿè®¡æ•°æ®åˆ°Redisï¼ˆå¯é€‰ï¼‰
func (c *Collector) SaveToRedis(ctx context.Context) error {
	if c.redisClient == nil {
		return nil
	}

	// ä¿å­˜å…¨å±€è®¡æ•°å™¨
	pipe := c.redisClient.Pipeline()
	pipe.Set(ctx, "stats:request_count", c.GetRequestCount(), 0)
	pipe.Set(ctx, "stats:error_count", c.GetErrorCount(), 0)

	// ä¿å­˜ç«¯ç‚¹ç»Ÿè®¡ï¼ˆç»Ÿä¸€åºåˆ—åŒ–ä¸ºJSONï¼Œé¿å…åˆ†æ•£çš„Hash keysï¼‰
	stats := c.GetStats()
	if len(stats) > 0 {
		endpointsData, err := json.Marshal(stats)
		if err == nil {
			pipe.Set(ctx, "stats:endpoints", endpointsData, 7*24*time.Hour)
		}
	}

	// ä¿å­˜æ—¶é—´åºåˆ—æ•°æ®ï¼ˆæœ€è¿‘48å°æ—¶ï¼‰
	requests := c.GetRequests()
	if len(requests) > 0 {
		// åªä¿å­˜æœ€è¿‘48å°æ—¶çš„æ•°æ®ï¼ˆçº¦2000-5000æ¡è®°å½•ï¼‰
		cutoff := time.Now().Unix() - 48*3600
		recentRequests := make([]RequestRecord, 0, len(requests))
		for _, req := range requests {
			if req.Timestamp >= cutoff {
				recentRequests = append(recentRequests, req)
			}
		}

		// ä½¿ç”¨JSONåºåˆ—åŒ–ä¿å­˜åˆ°Redisï¼ˆ7å¤©è¿‡æœŸï¼‰
		if len(recentRequests) > 0 {
			data, err := json.Marshal(recentRequests)
			if err == nil {
				pipe.Set(ctx, "stats:requests_timeline", data, 7*24*time.Hour)
			}
		}
	}

	_, err := pipe.Exec(ctx)
	return err
}

// LoadFromRedis ä»RedisåŠ è½½ç»Ÿè®¡æ•°æ®ï¼ˆå¯é€‰ï¼‰
func (c *Collector) LoadFromRedis(ctx context.Context) error {
	if c.redisClient == nil {
		return nil
	}

	// åŠ è½½å…¨å±€è®¡æ•°å™¨
	requestCount, _ := c.redisClient.Get(ctx, "stats:request_count").Int64()
	errorCount, _ := c.redisClient.Get(ctx, "stats:error_count").Int64()

	atomic.StoreInt64(&c.requestCount, requestCount)
	atomic.StoreInt64(&c.errorCount, errorCount)

	// åŠ è½½ç«¯ç‚¹ç»Ÿè®¡æ•°æ®
	endpointsData, err := c.redisClient.Get(ctx, "stats:endpoints").Bytes()
	if err == nil && len(endpointsData) > 0 {
		var endpoints map[string]*EndpointStats
		if err := json.Unmarshal(endpointsData, &endpoints); err == nil {
			c.mu.Lock()
			c.endpoints = endpoints
			c.mu.Unlock()
			log.Printf("ğŸ“Š ä»Redisæ¢å¤äº† %d ä¸ªç«¯ç‚¹çš„ç»Ÿè®¡æ•°æ®", len(endpoints))
		}
	}

	// åŠ è½½æ—¶é—´åºåˆ—æ•°æ®
	data, err := c.redisClient.Get(ctx, "stats:requests_timeline").Bytes()
	if err == nil && len(data) > 0 {
		var requests []RequestRecord
		if err := json.Unmarshal(data, &requests); err == nil {
			c.requestsMu.Lock()
			c.requests = requests
			c.requestsMu.Unlock()
			log.Printf("ğŸ“Š ä»Redisæ¢å¤äº† %d æ¡å†å²è¯·æ±‚è®°å½•", len(requests))
		}
	}

	return nil
}

// Close ä¼˜é›…å…³é—­ï¼ˆç®€åŒ–ç‰ˆæœ¬,æ— éœ€ç­‰å¾…goroutineï¼‰
func (c *Collector) Close() error {
	// ç®€åŒ–ç‰ˆæœ¬ä¸éœ€è¦å¤æ‚çš„å…³é—­é€»è¾‘
	return nil
}

// GetErrorCountPtr è¿”å›é”™è¯¯è®¡æ•°æŒ‡é’ˆï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
func (c *Collector) GetErrorCountPtr() *int64 {
	return &c.errorCount
}

// GetRequestCountPtr è¿”å›è¯·æ±‚è®¡æ•°æŒ‡é’ˆï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
func (c *Collector) GetRequestCountPtr() *int64 {
	return &c.requestCount
}

// GetDroppedEvents è·å–ä¸¢å¼ƒçš„äº‹ä»¶æ•°ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå§‹ç»ˆè¿”å›0ï¼‰
// ä¿ç•™æ­¤æ–¹æ³•ä»¥å…¼å®¹ç°æœ‰APIï¼Œä½†ç®€åŒ–ç‰ˆæœ¬ä¸ä¼šä¸¢å¼ƒäº‹ä»¶
func (c *Collector) GetDroppedEvents() int64 {
	return 0
}
